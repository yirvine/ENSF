{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yellowbrick\n",
    "from yellowbrick.datasets import load_spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 57)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(4600,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "X, y = load_spam()\n",
    "# TO DO: Print size and type of X and y\n",
    "print (X.shape)\n",
    "print(type(X))\n",
    "print (y.shape)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of missing values is  0 .\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missing = np.isnan(X).sum().sum()\n",
    "print(\"The total number of missing values is \", missing, \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 57)\n",
      "(230,)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_small = X.sample(frac=0.05, random_state=0)\n",
    "y_small = y.sample(frac=0.05, random_state=0)\n",
    "\n",
    "print(X_small.shape)\n",
    "print(y_small.shape)\n",
    "X_small_train, X_small_test, y_small_train, y_small_test = train_test_split(X_small, y_small, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score for X and y: 0.927\n",
      "Validation set score for X and y: 0.938\n",
      "\n",
      "Training set score for first 2 columns of X and y: 0.615\n",
      "Validation set score for first 2 columns of X and y: 0.593\n",
      "\n",
      "Training set score for small X and small y: 0.957\n",
      "Validation set score for small X and small y: 0.804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model_2_column = LogisticRegression(max_iter=2000)\n",
    "model_small = LogisticRegression(max_iter=2000)\n",
    "\n",
    "#1 - Implement the machine learning model with X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#2 - Implement the machine learning model with first 2 columns of X and y\n",
    "X_2columns = X.iloc[:, :2]\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2columns, y, test_size=0.2, random_state=0)\n",
    "model_2_column.fit(X_2_train, y_2_train)\n",
    "\n",
    "#3 - Implement the machine learning model with X_small and y_small\n",
    "model_small.fit(X_small_train, y_small_train)\n",
    "\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# logreg = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score for X and y: {:.3f}\".format(model.score(X_train, y_train)))\n",
    "print(\"Validation set score for X and y: {:.3f}\\n\".format(model.score(X_test, y_test)))\n",
    "\n",
    "print(\"Training set score for first 2 columns of X and y: {:.3f}\".format(model_2_column.score(X_2_train, y_2_train)))\n",
    "print(\"Validation set score for first 2 columns of X and y: {:.3f}\\n\".format(model_2_column.score(X_2_test, y_2_test)))\n",
    "\n",
    "print(\"Training set score for small X and small y: {:.3f}\".format(model_small.score(X_small_train, y_small_train)))\n",
    "print(\"Validation set score for small X and small y: {:.3f}\\n\".format(model_small.score(X_small_test, y_small_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. The training set score was higher with a smaller dataset (5% of the size) relative to the original dataset (0.927 compared to 0.957). The validation score was significantly higher for the larger dataset though (0.938 compared to 0.804). In the case of the set that used only the first 2 columns of data, the training and validation set scores were both markably lower than the other two datasets (0.615 for training and 0.593 for validation). This highlights the importance of including as many features as possible instead of just those found in the first 2 columns.\n",
    "\n",
    "2. A false positive would represent marking a regular e-mail as spam, and a false negative would represent marking a spam e-mail as a regular one. In my opinion, both situations are unfortunate (false negative or false positive) but a false negative is worse, because spam e-mails can potentially be very harmful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1030,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "X_concrete, y_concrete = load_concrete()\n",
    "# TO DO: Print size and type of X and y\n",
    "print (X_concrete.shape)\n",
    "print(type(X_concrete))\n",
    "print (y_concrete.shape)\n",
    "print(type(y_concrete))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of missing values is  0 .\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missing2 = np.isnan(X_concrete).sum().sum()\n",
    "print(\"The total number of missing values is \", missing2, \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5041945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_concrete = LinearRegression()\n",
    "\n",
    "#1 - Implement the machine learning model with X and y\n",
    "X_concrete_train, X_concrete_test, y_concrete_train, y_concrete_test = train_test_split(X_concrete, y_concrete, test_size=0.2, random_state=0)\n",
    "model_concrete.fit(X_concrete_train, y_concrete_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean squared Error: 110.34550122934108\n",
      "Test Mean Squared Error: 95.63533482690423\n",
      "\n",
      "Training R2 Score: 0.6090710418548884\n",
      "Test R2 Score: 0.6368981103411244\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict using the trained model\n",
    "y_train_pred = model_concrete.predict(X_concrete_train)\n",
    "y_test_pred = model_concrete.predict(X_concrete_test)\n",
    "\n",
    "# Compute the Mean Squared Error for training and test sets\n",
    "mse_train = mean_squared_error(y_concrete_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_concrete_test, y_test_pred)\n",
    "\n",
    "# Compute the R2 score for training and test sets\n",
    "r2_train = r2_score(y_concrete_train, y_train_pred)\n",
    "r2_test = r2_score(y_concrete_test, y_test_pred)\n",
    "\n",
    "# Print out the results\n",
    "print(\"Training Mean squared Error:\", mse_train)\n",
    "print(\"Test Mean Squared Error:\", mse_test)\n",
    "print(\"\\nTraining R2 Score:\", r2_train)\n",
    "print(\"Test R2 Score:\", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>110.345501</td>\n",
       "      <td>95.635335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 score</th>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.636898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Training accuracy Validation accuracy\n",
       "MSE             110.345501           95.635335\n",
       "R2 score          0.609071            0.636898"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame(index=['MSE', 'R2 score'], \n",
    "                       columns=['Training accuracy', 'Validation accuracy'])\n",
    "\n",
    "results['Training accuracy']['MSE'] = mse_train\n",
    "results['Training accuracy']['R2 score'] = r2_train\n",
    "results['Validation accuracy']['MSE'] = mse_test\n",
    "results['Validation accuracy']['R2 score'] = r2_test\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "No, the results provided a training accuracy of 0.61 in R2, and 0.64 in R2, which is relatively low in the context of predicting the dependent variable. This low R2 value could be due to various factors. One such factor could be that the 'X' data does not share a linear relationship with the 'y' data. Additionally, in this example there were 8 features, compared to the previous problem in which there were over 50 features - perhaps there are additional potential features that could have been included to help increase accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. Where did you source your code?\n",
    "    - I referenced some of the previous lecture and lab examples and https://www.geeksforgeeks.org/ for some syntax help. I completed the assignment in VSCode.\n",
    "1. In what order did you complete the steps?\n",
    "    - I completed them in order of the steps laid out, sequentially.\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "    - I didn't use any generative AI.\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "    - Yes, I had some trouble importing the right modules, but referencing the past lecture and lab examples helped clear some of those challenges up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "- In the first part, there was a clear relationship between the size of dataset (e.g. full dataset or 5% of dataset) and validation score. This is consistent with what we have been learning in lectures. Additionally, the fewer the features, the lower the accuracy seems to be. This applied in the first part when only 2 columns of X were used to predict y, where the validation and training accuracy both reduced significantly. \n",
    "\n",
    "In the 2nd part with the concrete data, there were only 8 features as opposed to 57, and the accuracy was significantly lower. This doesn't necessarily indicate that fewer features will always result in lower accuracy, since some features can be much stronger predictors than others, but it is a correlation that was apparent in this assignment.\n",
    "\n",
    "The second model also appeared to be underfitting, based on the low R2 score on both the validation and training sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I liked working through this Jupyter notebook. I also enjoyed analyzing the two datasets in different ways (binary logistic regression and then linear regression). I've always enjoyed data analysis so this assignment as a whole was relatively enjoyable. I did get slightly frustrated at times when I would get errors for failed imported modules, like those through sk.learn, but figured it out eventually after realizing it was entirely due to my own small mistakes that I was getting the errors in the first place.\n",
    "\n",
    "Though it was a simple example, this was a motivating assignment because I'm very curious to learn more about machine learning, so it's exciting to get a foot into the door with this very interesting field. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression:\n",
      "\n",
      "alpha = 0.001\n",
      "Training score: 0.56\n",
      "Validation score: 0.54\n",
      "\n",
      "alpha = 0.1\n",
      "Training score: 0.56\n",
      "Validation score: 0.54\n",
      "\n",
      "alpha = 1\n",
      "Training score: 0.56\n",
      "Validation score: 0.54\n",
      "\n",
      "alpha = 10\n",
      "Training score: 0.56\n",
      "Validation score: 0.54\n",
      "\n",
      "alpha = 100\n",
      "Training score: 0.55\n",
      "Validation score: 0.53\n",
      "Conclusion: Ridge regression has even lower accuracy regardless of which alpha value is used.\n",
      "\n",
      "\n",
      "Lasso Regression:\n",
      "\n",
      "alpha = 0.001\n",
      "Training set score: 0.56\n",
      "Validation set score: 0.53\n",
      "\n",
      "alpha = 0.1\n",
      "Training set score: 0.25\n",
      "Validation set score: -0.20\n",
      "\n",
      "alpha = 1\n",
      "Training set score: 0.11\n",
      "Validation set score: -0.25\n",
      "\n",
      "alpha = 10\n",
      "Training set score: 0.08\n",
      "Validation set score: 0.02\n",
      "\n",
      "alpha = 100\n",
      "Training set score: 0.00\n",
      "Validation set score: -0.00\n",
      "Conclusion: Lasso regression has even LOWER accuracy regardless of which alpha value is used. Alpha = 1 seems to provide the most accurate results.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "#Part 2: Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge0001 = Ridge(alpha=0.001).fit(X_train, y_train)\n",
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "ridge100 = Ridge(alpha=100).fit(X_train, y_train)\n",
    "\n",
    "print(\"Ridge Regression:\")\n",
    "print(\"\\nalpha = 0.001\")\n",
    "print(\"Training score: {:.2f}\".format(ridge0001.score(X_train, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(ridge0001.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nalpha = 0.1\")\n",
    "print(\"Training score: {:.2f}\".format(ridge01.score(X_train, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(ridge01.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nalpha = 1\")\n",
    "print(\"Training score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(ridge.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nalpha = 10\")\n",
    "print(\"Training score: {:.2f}\".format(ridge10.score(X_train, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(ridge10.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nalpha = 100\")\n",
    "print(\"Training score: {:.2f}\".format(ridge100.score(X_train, y_train)))\n",
    "print(\"Validation score: {:.2f}\".format(ridge100.score(X_test, y_test)))\n",
    "\n",
    "print(\"Conclusion: Ridge regression has even lower accuracy regardless of which alpha value is used.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Lasso Regression:\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso0001 = Lasso(alpha=0.001).fit(X_train, y_train)\n",
    "lasso01 = Lasso(alpha=0.1).fit(X_train, y_train)\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "lasso10 = Lasso(alpha=10).fit(X_train, y_train)\n",
    "lasso100 = Lasso(alpha=100).fit(X_train, y_train)\n",
    "\n",
    "print(\"Lasso Regression:\")\n",
    "print(\"\\nalpha = 0.001\")\n",
    "print(\"Training set score: {:.2f}\".format(lasso0001.score(X_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(lasso0001.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nalpha = 0.1\")\n",
    "print(\"Training set score: {:.2f}\".format(lasso01.score(X_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(lasso01.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nalpha = 1\")\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nalpha = 10\")\n",
    "print(\"Training set score: {:.2f}\".format(lasso10.score(X_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(lasso10.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nalpha = 100\")\n",
    "print(\"Training set score: {:.2f}\".format(lasso100.score(X_train, y_train)))\n",
    "print(\"Validation set score: {:.2f}\".format(lasso100.score(X_test, y_test)))\n",
    "\n",
    "print(\"Conclusion: Lasso regression has even LOWER accuracy regardless of which alpha value is used. Alpha = 1 seems to provide the most accurate results.\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
