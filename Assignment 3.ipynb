{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Yene Irvine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "# Importing required library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "# Loading the dataset\n",
    "X, y = load_concrete()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8014778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(max_depth=5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# 2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "\n",
    "# Instantiate Decision Tree with max_depth=5\n",
    "decision_tree_model = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "# Instantiate Random Forest with max_depth=5\n",
    "random_forest_model = RandomForestRegressor(max_depth=5, n_estimators=100)  \n",
    "\n",
    "# Instantiate Gradient Boosting with max_depth=5\n",
    "gradient_boosting_model = GradientBoostingRegressor(max_depth=5, n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "# 3. Implement each machine learning model with `X` and `y`\n",
    "# Fitting the models\n",
    "decision_tree_model.fit(X, y)\n",
    "random_forest_model.fit(X, y)\n",
    "gradient_boosting_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232a74e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 73.92986392437432\n",
      "Random Forest MSE: 47.234766549327965\n",
      "Gradient Boosting MSE: 23.554267550840727\n"
     ]
    }
   ],
   "source": [
    "# Additional imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Instantiate models (assuming you've done this in Step 3)\n",
    "dt_model = DecisionTreeRegressor(max_depth=5)\n",
    "rf_model = RandomForestRegressor(max_depth=5, n_estimators=100)\n",
    "gb_model = GradientBoostingRegressor(max_depth=5, n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "# Train models on training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate average MSE using cross-validation on training data for each model\n",
    "dt_mse = -cross_val_score(dt_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "rf_mse = -cross_val_score(rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "gb_mse = -cross_val_score(gb_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "# Print results\n",
    "print(\"Decision Tree MSE:\", dt_mse)\n",
    "print(\"Random Forest MSE:\", rf_mse)\n",
    "print(\"Gradient Boosting MSE:\", gb_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training Accuracy  Validation Accuracy\n",
      "DT          73.929864           104.561851\n",
      "RF          47.234767            63.141885\n",
      "GB          23.554268            56.589484\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# We already have the training MSEs. Let's get the validation MSEs.\n",
    "dt_val_mse = -cross_val_score(dt_model, X_test, y_test, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "rf_val_mse = -cross_val_score(rf_model, X_test, y_test, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "gb_val_mse = -cross_val_score(gb_model, X_test, y_test, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "# Using a dictionary to efficiently gather results\n",
    "model_results = {\n",
    "    'DT': {'Training Accuracy': dt_mse, 'Validation Accuracy': dt_val_mse},\n",
    "    'RF': {'Training Accuracy': rf_mse, 'Validation Accuracy': rf_val_mse},\n",
    "    'GB': {'Training Accuracy': gb_mse, 'Validation Accuracy': gb_val_mse}\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "results = pd.DataFrame(model_results).T  # Transpose to get models as index\n",
    "\n",
    "# Print results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training R2  Validation R2\n",
      "DT     0.736280       0.575590\n",
      "RF     0.828980       0.754671\n",
      "GB     0.916258       0.782746\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Calculate R^2 for training data\n",
    "dt_r2_train = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "rf_r2_train = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "gb_r2_train = cross_val_score(gb_model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "\n",
    "# Calculate R^2 for validation data\n",
    "dt_r2_val = cross_val_score(dt_model, X_test, y_test, cv=5, scoring='r2').mean()\n",
    "rf_r2_val = cross_val_score(rf_model, X_test, y_test, cv=5, scoring='r2').mean()\n",
    "gb_r2_val = cross_val_score(gb_model, X_test, y_test, cv=5, scoring='r2').mean()\n",
    "\n",
    "# Using a dictionary to efficiently gather results\n",
    "r2_results = {\n",
    "    'DT': {'Training R2': dt_r2_train, 'Validation R2': dt_r2_val},\n",
    "    'RF': {'Training R2': rf_r2_train, 'Validation R2': rf_r2_val},\n",
    "    'GB': {'Training R2': gb_r2_train, 'Validation R2': gb_r2_val}\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "results_r2 = pd.DataFrame(r2_results).T  # Transpose to get models as index\n",
    "\n",
    "# Print R^2 results\n",
    "print(results_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "\n",
    "\n",
    "MSE:\n",
    "\n",
    "Linear(previous assignment): Training MSE was 110.3 and Validation MSE was 95.65.\n",
    "DT: For Training, the MSE is 73.93, but it increases to 104.56 for Validation.\n",
    "RF: The Training MSE drops to 46.23 and continues to drop for Validation with 63.14.\n",
    "GB: The Training MSE reaches its lowest at 23.5542, and for Validation, it's 56.58.\n",
    "All the tree models have achieved a better fit on the training set than the linear model, as seen from the decreased training MSEs. On the validation side, RF and GB have outperformed the linear model, while DT struggled a bit.\n",
    "\n",
    "R2 Score:\n",
    "\n",
    "Linear (previous assignment): The Training and Validation R2 were 0.609 and 0.637 respectively.\n",
    "DT: Achieved a Training R2 of 0.736, but slipped to 0.576 on Validation.\n",
    "RF: Improved Training with an R2 of 0.829 and did well on Validation with 0.755.\n",
    "GB: Tops the list with Training R2 at 0.916 and Validation R2 at 0.783.\n",
    "Every tree model has bettered the training R^2 compared to the linear model. For validation, RF and GB models have gone past the linear model, but DT has taken a step back.\n",
    "\n",
    "\n",
    "2. Out of the models you tested, which model would you select for this dataset and why?\n",
    "Considering both our metrics, the Gradient Boosting (GB) model appears to be the best. It's demonstrating the best balance between understanding the training data and predicting  unseen data, as indicated by the highest R^2 and the lowest MSE values, especially on the training set.\n",
    "\n",
    "\n",
    "3. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "To improve results, we could experiment with model settings/tuning parameters. Using techniques like GridSearchCV or RandomizedSearchCV, we could try different parameter combinations like n_estimators, max_depth, and so on.\n",
    "\n",
    "We could also dive deeper into our data and perhaps come up with new features, or adjust existing ones, to boost our model's understanding. This may involve tasks like standardizing data values, which can be especially beneficial for Gradient Boosting models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "\n",
    "1. Where did you source your code?\n",
    "I referred to examples from the labs and previous lectures as well as the odd Google, referring the website https://www.geeksforgeeks.org/ at times.\n",
    "\n",
    "2. In what order did you complete the steps?\n",
    "I completed the steps chronologically through the Jupyter notebook.\n",
    "\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "I used ChatGPT to debug at times when I encountered errors. It turned out I just had some syntax issues. \n",
    "\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "Honestly, not really. I cited the examples and use geeksforgeeks.org and that helped keep this relatively straightfroward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (178, 13)\n",
      "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Size of y: (178,)\n",
      "Type of y: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Defining the column headers as they are not provided in the dataset\n",
    "column_headers = [\n",
    "    \"Class\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\", \n",
    "    \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\", \n",
    "    \"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"\n",
    "]\n",
    "\n",
    "# Loading the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "wine_data = pd.read_csv(url, header=None, names=column_headers)\n",
    "\n",
    "# Splitting the dataset into feature matrix 'X' and target vector 'y'\n",
    "X = wine_data.drop(\"Class\", axis=1)\n",
    "y = wine_data[\"Class\"]\n",
    "\n",
    "# Printing the size and type of 'X' and 'y'\n",
    "print(f\"Size of X: {X.shape}\")\n",
    "print(f\"Type of X: {type(X)}\")\n",
    "print(f\"\\nSize of y: {y.shape}\")\n",
    "print(f\"Type of y: {type(y)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0      1    14.23        1.71  2.43               15.6        127   \n",
      "1      1    13.20        1.78  2.14               11.2        100   \n",
      "2      1    13.16        2.36  2.67               18.6        101   \n",
      "3      1    14.37        1.95  2.50               16.8        113   \n",
      "4      1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Printing the first five rows of the dataset\n",
    "print(wine_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                           0\n",
      "Alcohol                         0\n",
      "Malic acid                      0\n",
      "Ash                             0\n",
      "Alcalinity of ash               0\n",
      "Magnesium                       0\n",
      "Total phenols                   0\n",
      "Flavanoids                      0\n",
      "Nonflavanoid phenols            0\n",
      "Proanthocyanins                 0\n",
      "Color intensity                 0\n",
      "Hue                             0\n",
      "OD280/OD315 of diluted wines    0\n",
      "Proline                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Checking for missing values in each column\n",
    "missing_values = wine_data.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Count the number of samples for each wine type\n",
    "wine_counts = y.value_counts()\n",
    "print(wine_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be4b5c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Training accuracy  Validation accuracy\n",
      "SVC                    0.703743             0.663492\n",
      "DecisionTree           0.976165             0.882063\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# Step 3\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "svc_model = SVC()\n",
    "dt_model = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "svc_model.fit(X, y)\n",
    "dt_model.fit(X, y)\n",
    "\n",
    "# Step 4\n",
    "# Import necessary libraries for validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# List of models\n",
    "models = {\n",
    "    \"SVC\": svc_model,\n",
    "    \"DecisionTree\": dt_model\n",
    "}\n",
    "\n",
    "# Dictionary to store training and validation accuracies for each model\n",
    "accuracy_data = {}\n",
    "\n",
    "# Validate each model\n",
    "for name, model in models.items():\n",
    "    scores = cross_validate(model, X, y, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    accuracy_data[name] = {\n",
    "        \"Training accuracy\": scores['train_score'].mean(),\n",
    "        \"Validation accuracy\": scores['test_score'].mean()\n",
    "    }\n",
    "\n",
    "    \n",
    "#Step 5\n",
    "\n",
    "# Convert accuracy_data dictionary to pandas DataFrame\n",
    "results = pd.DataFrame(accuracy_data).T  # The 'T' is for transpose, to have the model names as rows.\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Train the DecisionTree model using the training set\n",
    "best_model = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize confusion matrix using heatmap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g', xticklabels=y.unique(), yticklabels=y.unique())\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.89      0.94        19\n",
      "           2       0.91      0.95      0.93        22\n",
      "           3       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.95      0.95      0.95        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print classification report\n",
    "# Convert unique class numbers to strings\n",
    "target_names = [str(label) for label in y.unique()]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "The DecisionTree classifier appears to be a better model for this dataset based on both training and validation accuracy, scoring 0.976 and 0.882 respectively, compared to 0.704 training accuracy and 0.663 validation accuracy for SVC.  \n",
    "\n",
    "The discrepancy between the training and validation accuracies for the DecisionTree model seems to suggest potential overfitting. This discrepancy is not so significant for SVC.\n",
    "\n",
    "2. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "Data Complexity: Decision trees are good at handling non-linear patterns and feature interactions, which may be present in the wine data. \n",
    "\n",
    "Feature Scaling: SVMs are sensitive to data scale, needing standardized features to work well. Decision trees are not sensitive to scaling. \n",
    "\n",
    "3. How many samples were incorrectly classified in step 5.2? \n",
    "3\n",
    "\n",
    "4. In this case, is maximizing precision or recall more important? Why?\n",
    "Precision is the ratio of true positive predictions to total predicted positives, which is important when the cost of false positives is high. On the other hand, recall determines the ratio of true positive predictions to all actual positives, making it essential when overlooking positive samples could lead to considerable consequences.  In this context, recall measures how many of the actual positive samples were correctly identified, so for the wine dataset, precision must be maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "Just like in Part 1, I referred to previous Labs and Lecture notes.\n",
    "\n",
    "1. In what order did you complete the steps?\n",
    "I completed them all chronologically through this notebook.\n",
    "\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "I used ChatGPT to diagnose errors I kept encountering during Step 5 when trying to print the classification report and generate the confusion matrix.\n",
    "\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "No, only really the above ones where I kept encountering errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "As discussed in lectures, models with high training accuracy and significantly lower validation/test accuracy can be indicative of high variance / overfitting. In contrast, models that underperform both in training and validation might be in a high bias scenario, which is characterized as underfitting. In these results, the Decision Tree seems to lean more towards the high variance side (overfitting), whereas the SVC might be underfitting.\n",
    "\n",
    "Another observation with the wine dataset is that the macro average and weighted average values of precision, recall, and F1-score are all in the mid-90s, reiterating that the model's performance is consistent across the classes. Class 1 specifically had an impressive precision of 100%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "It was satisfying to get a visual representation in the form of a confusion matrix at the end. There were challenging moments throughout the assignment, specifically in trying to get the syntax exactly right to prevent errors, but everything was relatively straightforward especially using the previous labs and lectures as a reference. At the end of the day, the content is relatively intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
